The vpx multi-\/format codec S\+DK provides a unified interface amongst its supported codecs. This abstraction allows applications using this S\+DK to easily support multiple video formats with minimal code duplication or \char`\"{}special casing.\char`\"{} This section describes the interface common to all codecs. For codec-\/specific details, see the \hyperlink{group__codecs}{Supported Codecs} page.

The following sections are common to all codecs\+:
\begin{DoxyItemize}
\item \hyperlink{usage_usage_types}{Important Data Types}
\item \hyperlink{usage_usage_features}{Features}
\item \hyperlink{usage_usage_init}{Initialization}
\item \hyperlink{usage_usage_errors}{Error Handling}
\end{DoxyItemize}

For more information on decoder and encoder specific usage, see the following pages\+: \begin{DoxyItemize}
\item \hyperlink{usage_decode}{Decoding} \item \hyperlink{usage_encode}{Encoding}\end{DoxyItemize}
\hypertarget{usage_usage_types}{}\subsection{Important Data Types}\label{usage_usage_types}
There are two important data structures to consider in this interface.\hypertarget{usage_usage_ctxs}{}\subsubsection{Contexts}\label{usage_usage_ctxs}
A context is a storage area allocated by the calling application that the codec may write into to store details about a single instance of that codec. Most of the context is implementation specific, and thus opaque to the application. The context structure as seen by the application is of fixed size, and thus can be allocated with automatic storage or dynamically on the heap.

Most operations require an initialized codec context. Codec context instances are codec specific. That is, the codec to be used for the encoded video must be known at initialization time. See \hyperlink{group__codec_gad03e2dfa6ae511db7d25be6bbb336233}{vpx\+\_\+codec\+\_\+ctx\+\_\+t} for further information.\hypertarget{usage_usage_ifaces}{}\subsubsection{Interfaces}\label{usage_usage_ifaces}
A codec interface is an opaque structure that controls how function calls into the generic interface are dispatched to their codec-\/specific implementations. Applications \hyperlink{rfc2119_MUSTNOT}{M\+U\+ST N\+OT} attempt to examine or override this storage, as it contains internal implementation details likely to change from release to release.

Each supported codec will expose an interface structure to the application as an {\ttfamily extern} reference to a structure of the incomplete type \hyperlink{group__codec_gae99c3b04f4a567a311211cce3ae6b83b}{vpx\+\_\+codec\+\_\+iface\+\_\+t}.\hypertarget{usage_usage_features}{}\subsection{Features}\label{usage_usage_features}
Several \char`\"{}features\char`\"{} are defined that are optionally implemented by codec algorithms. Indeed, the same algorithm may support different features on different platforms. The purpose of defining these features is that when they are implemented, they conform to a common interface. The features, or capabilities, of an algorithm can be queried from it\textquotesingle{}s interface by using the \hyperlink{group__codec_ga43adff58759093401235fb99247c82b8}{vpx\+\_\+codec\+\_\+get\+\_\+caps()} method. Attempts to invoke features not supported by an algorithm will generally result in \hyperlink{group__codec_ggada1084710837ad363b92f2379dd2b8d2a4470784ba5a3ef84dc0697d5489dd292}{V\+P\+X\+\_\+\+C\+O\+D\+E\+C\+\_\+\+I\+N\+C\+A\+P\+A\+B\+LE}.

Currently defined decoder features include\+:
\begin{DoxyItemize}
\item \hyperlink{usage_decode_usage_cb}{Callback Based Decoding}
\item \hyperlink{usage_decode_usage_postproc}{Postprocessing}
\end{DoxyItemize}\hypertarget{usage_usage_init}{}\subsection{Initialization}\label{usage_usage_init}
To initialize a codec instance, the address of the codec context and interface structures are passed to an initialization function. Depending on the \hyperlink{usage_usage_features}{Features} that the codec supports, the codec could be initialized in different modes.

To prevent cases of confusion where the A\+BI of the library changes, the A\+BI is versioned. The A\+BI version number must be passed at initialization time to ensure the application is using a header file that matches the library. The current A\+BI version number is stored in the preprocessor macros \hyperlink{group__codec_gaf7e9cad2df0f81679b881f46740ad097}{V\+P\+X\+\_\+\+C\+O\+D\+E\+C\+\_\+\+A\+B\+I\+\_\+\+V\+E\+R\+S\+I\+ON}, \hyperlink{group__encoder_gaa4f0b52293c08ba672429c3a03648b9d}{V\+P\+X\+\_\+\+E\+N\+C\+O\+D\+E\+R\+\_\+\+A\+B\+I\+\_\+\+V\+E\+R\+S\+I\+ON}, and \hyperlink{group__decoder_ga462b459e7ae13937e1eae1776245db12}{V\+P\+X\+\_\+\+D\+E\+C\+O\+D\+E\+R\+\_\+\+A\+B\+I\+\_\+\+V\+E\+R\+S\+I\+ON}. For convenience, each initialization function has a wrapper macro that inserts the correct version number. These macros are named like the initialization methods, but without the \+\_\+ver suffix.

The available initialization methods are\+: \begin{DoxyItemize}
\item \hyperlink{group__encoder_ga3d490a2a9a6acd7c9ef82a603155f3cf}{vpx\+\_\+codec\+\_\+enc\+\_\+init} (calls \hyperlink{group__encoder_ga1472ec347010fe5ef32766a299e57cc4}{vpx\+\_\+codec\+\_\+enc\+\_\+init\+\_\+ver()}) \item \hyperlink{group__encoder_gad7ae1d930cf110d6fe70beafeacfd9c7}{vpx\+\_\+codec\+\_\+enc\+\_\+init\+\_\+multi} (calls \hyperlink{group__encoder_ga1c0415984a5469687f53613a5471f53d}{vpx\+\_\+codec\+\_\+enc\+\_\+init\+\_\+multi\+\_\+ver()}) \item \hyperlink{group__decoder_ga8c2f0b12f1bd4927eb3c68b01eab19d3}{vpx\+\_\+codec\+\_\+dec\+\_\+init} (calls \hyperlink{group__decoder_ga6435c3e8cb9408f1c0c3d052a3a577b7}{vpx\+\_\+codec\+\_\+dec\+\_\+init\+\_\+ver()})\end{DoxyItemize}
\hypertarget{usage_usage_errors}{}\subsection{Error Handling}\label{usage_usage_errors}
Almost all codec functions return an error status of type \hyperlink{group__codec_gada1084710837ad363b92f2379dd2b8d2}{vpx\+\_\+codec\+\_\+err\+\_\+t}. The semantics of how each error condition should be processed is clearly defined in the definitions of each enumerated value. Error values can be converted into A\+S\+C\+II strings with the \hyperlink{group__codec_ga4d265df00d42b36a4f0e3eb83fc22c5e}{vpx\+\_\+codec\+\_\+error()} and \hyperlink{group__codec_gaaddf5c1f609ef18c7c8800d102fcefa6}{vpx\+\_\+codec\+\_\+err\+\_\+to\+\_\+string()} methods. The difference between these two methods is that \hyperlink{group__codec_ga4d265df00d42b36a4f0e3eb83fc22c5e}{vpx\+\_\+codec\+\_\+error()} returns the error state from an initialized context, whereas \hyperlink{group__codec_gaaddf5c1f609ef18c7c8800d102fcefa6}{vpx\+\_\+codec\+\_\+err\+\_\+to\+\_\+string()} can be used in cases where an error occurs outside any context. The enumerated value returned from the last call can be retrieved from the {\ttfamily err} member of the decoder context as well. Finally, more detailed error information may be able to be obtained by using the \hyperlink{group__codec_ga29273cb552ed1a437fe263c4a0a54300}{vpx\+\_\+codec\+\_\+error\+\_\+detail()} method. Not all errors produce detailed error information.

In addition to error information, the codec library\textquotesingle{}s build configuration is available at runtime on some platforms. This information can be returned by calling \hyperlink{group__codec_ga20922bad85472e76d5f61c21cb423af7}{vpx\+\_\+codec\+\_\+build\+\_\+config()}, and is formatted as a base64 coded string (comprised of characters in the set \mbox{[}a-\/z\+\_\+a-\/\+Z0-\/9+/\mbox{]}). This information is not useful to an application at runtime, but may be of use to vpx for support.\hypertarget{usage_usage_deadline}{}\subsection{Deadline}\label{usage_usage_deadline}
Both the encoding and decoding functions have a {\ttfamily deadline} parameter. This parameter indicates the amount of time, in microseconds (us), that the application wants the codec to spend processing before returning. This is a soft deadline -- that is, the semantics of the requested operation take precedence over meeting the deadline. If, for example, an application sets a {\ttfamily deadline} of 1000us, and the frame takes 2000us to decode, the call to \hyperlink{group__decoder_ga3441e157a7a69108bca9a069f2ee8e0d}{vpx\+\_\+codec\+\_\+decode()} will return after 2000us. In this case the deadline is not met, but the semantics of the function are preserved. If, for the same frame, an application instead sets a {\ttfamily deadline} of 5000us, the decoder will see that it has 3000us remaining in its time slice when decoding completes. It could then choose to run a set of \hyperlink{usage_decode_usage_postproc}{Postprocessing} filters, and perhaps would return after 4000us (instead of the allocated 5000us). In this case the deadline is met, and the semantics of the call are preserved, as before.

The special value {\ttfamily 0} is reserved to represent an infinite deadline. In this case, the codec will perform as much processing as possible to yield the highest quality frame.

By convention, the value {\ttfamily 1} is used to mean \char`\"{}return as fast as
 possible.\char`\"{} \hypertarget{usage_decode}{}\subsection{Decoding}\label{usage_decode}
The \hyperlink{group__decoder_ga3441e157a7a69108bca9a069f2ee8e0d}{vpx\+\_\+codec\+\_\+decode()} function is at the core of the decode loop. It processes packets of compressed data passed by the application, producing decoded images. The decoder expects packets to comprise exactly one image frame of data. Packets \hyperlink{rfc2119_MUST}{M\+U\+ST} be passed in decode order. If the application wishes to associate some data with the frame, the {\ttfamily user\+\_\+priv} member may be set. The {\ttfamily deadline} parameter controls the amount of time in microseconds the decoder should spend working on the frame. This is typically used to support adaptive \hyperlink{usage_decode_usage_postproc}{Postprocessing} based on the amount of free C\+PU time. For more information on the {\ttfamily deadline} parameter, see \hyperlink{usage_usage_deadline}{Deadline}.

samples\hypertarget{usage_decode_usage_cb}{}\subsubsection{Callback Based Decoding}\label{usage_decode_usage_cb}
There are two methods for the application to access decoded frame data. Some codecs support asynchronous (callback-\/based) decoding \hyperlink{usage_usage_features}{Features} that allow the application to register a callback to be invoked by the decoder when decoded data becomes available. Decoders are not required to support this feature, however. Like all \hyperlink{usage_usage_features}{Features}, support can be determined by calling \hyperlink{group__codec_ga43adff58759093401235fb99247c82b8}{vpx\+\_\+codec\+\_\+get\+\_\+caps()}. Callbacks are available in both frame-\/based and slice-\/based variants. Frame based callbacks conform to the signature of \hyperlink{group__cap__put__frame_gab570c589b333dcccf61b3164cc95234e}{vpx\+\_\+codec\+\_\+put\+\_\+frame\+\_\+cb\+\_\+fn\+\_\+t} and are invoked once the entire frame has been decoded. Slice based callbacks conform to the signature of \hyperlink{group__cap__put__slice_gaab464940e2102efa0604b7788eb2e3b1}{vpx\+\_\+codec\+\_\+put\+\_\+slice\+\_\+cb\+\_\+fn\+\_\+t} and are invoked after a subsection of the frame is decoded. For example, a slice callback could be issued for each macroblock row. However, the number and size of slices to return is implementation specific. Also, the image data passed in a slice callback is not necessarily in the same memory segment as the data will be when it is assembled into a full frame. For this reason, the application \hyperlink{rfc2119_MUST}{M\+U\+ST} examine the rectangles that describe what data is valid to access and what data has been updated in this call. For all their additional complexity, slice based decoding callbacks provide substantial speed gains to the overall application in some cases, due to improved cache behavior.\hypertarget{usage_decode_usage_frame_iter}{}\subsubsection{Frame Iterator Based Decoding}\label{usage_decode_usage_frame_iter}
If the codec does not support callback based decoding, or the application chooses not to make use of that feature, decoded frames are made available through the \hyperlink{group__decoder_ga0e231c3a5ce445fdb2268d741da97500}{vpx\+\_\+codec\+\_\+get\+\_\+frame()} iterator. The application initializes the iterator storage (of type \hyperlink{group__codec_ga6ea348f76b1f8a1fe50e14db684146c6}{vpx\+\_\+codec\+\_\+iter\+\_\+t}) to N\+U\+LL, then calls vpx\+\_\+codec\+\_\+get\+\_\+frame repeatedly until it returns N\+U\+LL, indicating that all images have been returned. This process may result in zero, one, or many frames that are ready for display, depending on the codec.\hypertarget{usage_decode_usage_postproc}{}\subsubsection{Postprocessing}\label{usage_decode_usage_postproc}
Postprocessing is a process that is applied after a frame is decoded to enhance the image\textquotesingle{}s appearance by removing artifacts introduced in the compression process. It is not required to properly decode the frame, and is generally done only when there is enough spare C\+PU time to execute the required filters. Codecs may support a number of different postprocessing filters, and the available filters may differ from platform to platform. Embedded devices often do not have enough C\+PU to implement postprocessing in software. The filter selection is generally handled automatically by the codec, depending on the amount of time remaining before hitting the user-\/specified \hyperlink{usage_usage_deadline}{Deadline} after decoding the frame. \hypertarget{usage_encode}{}\subsection{Encoding}\label{usage_encode}
The \hyperlink{group__encoder_gaf990542e2aeb389f05fae3e9c7803639}{vpx\+\_\+codec\+\_\+encode()} function is at the core of the encode loop. It processes raw images passed by the application, producing packets of compressed data. The {\ttfamily deadline} parameter controls the amount of time in microseconds the encoder should spend working on the frame. For more information on the {\ttfamily deadline} parameter, see \hyperlink{usage_usage_deadline}{Deadline}.

samples 